---
layout: post
title:  "ChatGPT, résultats, problèmes, principe et perspectives"
date:   2023-03-11 19:55:40 +0100
categories: jekyll update
---
## <span style="color:#000000">Applications</span>
ChatGPT est utilisé dans une grande variété d'applications et à des fins différentes mais on peut tirer trois catégories bien apparentes d'utilisations de ChatGPT :
# <span style="color:#3a5069">Créativité</span>
Le but ici est d'assister l'utilisateur dans des tâches créatives telles que la génération de texte dans un style particulier (imiter Shakespeare par exemple) ou d'utiliser un ton particulier (sarcastique par exemple). Il est aussi utilisé afin de donner des idées comme la suggestion de cadeaux d'anniversaire, la suggestion d'événements à organiser dans le cadre du travail etc.
Nous retrouvons par exemple [cet utilisateur sur Reddit](https://www.reddit.com/r/ChatGPT/comments/111qwos/beautiful_advice_for_to_how_cope_with_my_aging/) qui demande à ChatGPT ce qu'il peut faire pour faire face au fait que son chien devient âgé et pour surmonter la peur de sa mort.
![Alt text](https://i.redd.it/pojhvg5es3ia1.jpg)

# <span style="color:#3a5069">Programmation</span>
ChatGPT peut aider dans la programmation en générant du code soit pour compléter du code existant, soit pour créer de nouvelles fonctions, soit pour tester d'autres fonctions etc. Il peut aussi être utilisé pour débugger et corriger la syntaxe ou encore aider avec des commandes Linux et Git. On retrouve par exemple [cette créatrice de contenu](https://www.youtube.com/watch?v=VznoKyh6AXs&t=1s) qui nous apprend comment apprendre la programmation rapidement en utilisant ChatGPT.
![Alt text](https://raw.githubusercontent.com/TAHTAH98/tahtah98.github.io/main/images/learn_with_chatgpt.png)


# <span style="color:#3a5069">Corvées</span>
ChatGPT peut aussi être utilisé pour nous aider dans nos tâches quotidiennes et certaines corvées comme l'écriture et la ré-écriture de mails, l'organisation de tâche dans un emploi du temps, l'organisation de plats et la suggestions de recettes à partir de ce qui est dans le réfrigérateur etc. On retrouve [l'extension ChatGPT Writer](https://chrome.google.com/webstore/detail/chatgpt-writer-write-mail/pdnenlnelpdomajfejgapbdpmjkfpjkp) sur Google Chrome qui permet d'écrire des mails rapidement et efficacement en utilisant ChatGPT.
![Alt text](https://raw.githubusercontent.com/TAHTAH98/tahtah98.github.io/main/images/chatgptwriter.png)

## Problèmes
Bien que ChatGPT soit d'apparence une révolution par rapport aux modèles de langages précédents, il reste un modèle de la famille des modèles GPT3 et ce qui fait son unicité est la manière dont il est entraîné [1]. Ceci implique aussi qu'il y a plusieurs types de problèmes, des problèmes liés au fait qu'il soit un algorithme de machine learning, et puis des problèmes liés au fait à comment il a été fine-tuné, donc à ce qui fait son unicité. Pour traider des problèmes autour de ChatGPT, nous distinguons les problèmes éthiques des problèmes qu'on qualifie de "techniques".

# <span style="color:#3a5069">Éthiques</span>
On trouve plusieurs problèmes éthiques dont :
- Biais : ChatGPT étant un modèle de machine learning entraînés sur un immense volume de données tirés de l'internet, il est sensible aux biais qui se trouvent dans ces données et il les reproduit. Grâce aux actions d'OpenAI, on a remarqué que le modèle est de plus en plus insensibles aux biais et refuse de produire des réponses racistes, sexistes, violentes ou autres.
- Usurpation : Les utilisateurs peuvent demander à ChatGPT d'écrire et de parler comme une autre personne, et c'est surtout les célébrités qui sont sujettes à ça puisque leur contenu est plus répandu dans les données sur lesquelles a été entraîné ChatGPT mais on peut facilement envisager un fine-tuning d'un modèle tel que ChatGPT sur des posts, des commentaires et autres d'une personne spécifique. Par exemple, [on peut demander à l'IA de Bing de se faire passer pour The Rock, Biden ou Trump](https://www.bleepingcomputer.com/news/microsoft/bing-chat-has-a-secret-celebrity-mode-to-impersonate-celebrities/)
![Alt text](https://raw.githubusercontent.com/TAHTAH98/tahtah98.github.io/main/images/trump_biden.png)
- Harcélement : On peut imaginer ChatGPT utilisé pour le cyber-harcèlement, pour du contenu violent, gore et dépassant les limites de la morale et de l'éthique. En effet, bien qu'il y ait des limites imposées par OpenAI, les méthodes [DAN](https://www.reddit.com/r/ChatGPT/comments/10tevu1/new_jailbreak_proudly_unveiling_the_tried_and/) permettent de dépasser ces limites en faisant à ChatGPT prendre le rôle d'une IA qui ne connaît pas de limites. 
- Désinformation : Puisque ChatGPT peut créer du contenu qui ressemble de près à du contenu créer par des personnes réelles, il peut facilement être utiliser pour produire de la désinformation en masse. On retrouve [cet article du The New York Times](https://www.nytimes.com/2023/02/08/technology/ai-chatbots-disinformation.html) qui en parle.
- Malware : Bienq qu'il n'y ait pas encore d'articles qui parlent de la production de malware complètement gérée par ChatGPT, on peut imaginer qu'il va aider grâce à ses capacités de génération de code dans l'accélération de production de ce type de programmes ainsi que leur efficacité. D'ailleurs, puisque on a déjà connu des instances où [GitHub Copilot a généré du codes avec des invulnérabilités](https://github.blog/2023-02-14-github-copilot-now-has-a-better-ai-model-and-new-capabilities/), il ne serait pas étonnant que ChatGPT génére aussi complète un code avec des invulnérabilités si le code de base en contient déjà.

# <span style="color:#3a5069">Techniques</span>
On peut identifier deux problèmes techniques majeurs liés à la manière dont est fine-tuné ChatGPT : 
- Il peut générer du contenu "trompeur" dans le sens où bien que le modèle sait répondre et exécuter une requête, il affirmera l'inverse. [Cet utilisateur](https://www.reddit.com/r/GPT3/comments/zb4msc/speaking_to_chatgpt_in_perfect_danish_while_it/) demande à ChatGPT de parler Danois et ce dernier lui répond en Danois qu'il ne sait pas parler cette langue.
- Il peut aussi générer du contenu "mensonger" dans le sens où bien que le modèle sache que sa réponse est fausse, il va quand même l'envoyer à l'utilisateur. [Cet article](https://astralcodexten.substack.com/p/elk-and-the-problem-of-truthful-ai) explique qu'on retrouve ce problème dans tous les grands modèles de language fine-tuné avec le Reinforcement Learning from Human Feedback (RLFH), tels que ChatGPT. L'exemple de l'article est ci-dessous :
![Alt text](https://raw.githubusercontent.com/TAHTAH98/tahtah98.github.io/main/images/llm_dumb.png)
On peut aussi identifier un problème lié à la décision autour des données sur lesquelles entraîné les modèles de langage. Des recherches d'interprétabilité ont trouvé que, lorsqu'utilisés, certains tokens conduisent à des comportements étranges et inattendus de la part des modèles de langages (dont ChatGPT). On tire de [l'article en question](https://www.alignmentforum.org/posts/aPeJE8bSo6rAFoLqg/solidgoldmagikarp-plus-prompt-generation) l'exemple suivant :
![Alt text](https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675551031/mirroredImages/aPeJE8bSo6rAFoLqg/ipduymkhhntbgvjerqda.png)
Bien que ce comportement ne pose pas de problème en soi et est facilement réglable, s'il n'est pas fixé, on peut facilement imaginer des problèmes lors de l'utilisation de tels modèles dans la recherche de documents, de vidéos etc. dans une large base de données.


## Principe

## Perspectives

## Bibliographie

[1] https://openai.com/blog/chatgpt